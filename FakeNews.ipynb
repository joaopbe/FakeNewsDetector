{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(l):\n",
    "    \"\"\"\n",
    "    Remove English stopwords from a list of strings.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after stop words are removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    return [w for w in l if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    \"\"\"\n",
    "    Tokenize a string.\n",
    "\n",
    "    Args:\n",
    "        s: String to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        A list of words as the result of tokenization.\n",
    "    \"\"\"\n",
    "    return word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(l):\n",
    "    \"\"\"\n",
    "    Perform stemming and lemmatization on a list of words.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after being stemmed and lemmatized.\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer ()\n",
    "    stemmed = [ps.stem(w) for w in l]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w) for w in stemmed]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processor(s):\n",
    "    \"\"\"\n",
    "    Perform all pre processing before Count Vectorizer\n",
    "\n",
    "    Args:\n",
    "      s: series of texts\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.str.replace(r'[^\\w\\s]+', '')\n",
    "    s = s.str.lower()\n",
    "    \n",
    "    return [' '.join(stem_and_lemmatize(remove_stopwords(tokenize(el)))) for el in s] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_fit(X,y,model,parameters,modelname):\n",
    "    \n",
    "    pipe_model = Pipeline([('vect', CountVectorizer(dtype=np.int16)),('tfidf', TfidfTransformer()),\\\n",
    "                     ('clf', model)])\n",
    "\n",
    "    model = GridSearchCV(pipe_model, parameters, cv=5)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    pickle.dump(model, open(modelname + '.sav', 'wb'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_fit2(X,y,model,parameters,modelname):\n",
    "    \n",
    "    model = GridSearchCV(model, parameters, cv=5)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    pickle.dump(model, open(modelname + '.sav', 'wb'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(X_test,y_test, model,modelname):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(modelname ,'Optimal Parameters :       ', model.cv_results_ ['params'] [np.argmin(model.cv_results_['rank_test_score'])])\n",
    "    print(modelname ,'Cross Validation Accuracy: ', round(model.cv_results_ ['mean_test_score'] [np.argmin(model.cv_results_['rank_test_score'])]*100,2), '%', '\\n')\n",
    "\n",
    "    print(modelname ,'Accuracy:  ', round(model.score(X_test, y_test) * 100,2) , '%')\n",
    "    print(modelname ,'Precision: ', round(precision_score(y_test,y_pred) *100,2), '%')\n",
    "    print(modelname ,'Recall:    ', round(recall_score(y_test,y_pred) *100,2), '%')      \n",
    "    print(modelname ,'F1-Score:  ', round(f1_score(y_test,y_pred),2), '\\n')  \n",
    "\n",
    "    cmap = sns.cubehelix_palette(40, hue=0.05, rot=0, light=0.7, dark=0.2,as_cmap=True)\n",
    "    sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, annot_kws={'fontsize':14,'fontweight':'bold'},fmt='d', cmap=cmap)\n",
    "    plt.title(modelname +' Confusion Matrix')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Reality')\n",
    "    plt.xticks([0.5,1.5], labels=['fake', 'true'])\n",
    "    plt.yticks([0.5,1.5], labels=['fake', 'true'], va='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Kaggle - All the News](https://www.kaggle.com/snapcrack/all-the-news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the news Dataset from Kaggle with 150K articles from 15 different publications (\"true news\")\n",
    "\n",
    "all_news1 = pd.read_csv('all-the-news/articles1.csv', index_col=0)\n",
    "all_news2 = pd.read_csv('all-the-news/articles2.csv', index_col=0)\n",
    "all_news3 = pd.read_csv('all-the-news/articles3.csv', index_col=0)\n",
    "all_news = pd.concat([all_news1, all_news2, all_news3])\n",
    "\n",
    "all_news = all_news.loc[~all_news.title.isnull()] \n",
    "\n",
    "tn_df = all_news.loc[:, ['title', 'content']]\n",
    "tn_df['target'] = 0 # insert target column with value 0 - is not fake news\n",
    "tn_df = tn_df.sample(12403) # sample 12000 samples to have a balanced DS with the fake news\n",
    "tn_df.rename(columns={'content':'text'}, inplace=True) #align column names with fake news\n",
    "tn_df.isnull().sum() # Validate there are no NaN present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Kaggle - Getting Real about Fake News](https://www.kaggle.com/mrisdal/fake-news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     680\n",
       "text       46\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fake news dataset from Kaggle\n",
    "fake_news = pd.read_csv('fake.csv')\n",
    "\n",
    "# get only relevant columns & english language\n",
    "fn_df=fake_news.loc[fake_news.language == 'english',['title','text']] \n",
    "fn_df['target'] = 1 # insert target column with value 1 - is fake news\n",
    "fn_df.isnull().sum() # Validate for NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are null values, but they do not coincide in title/text. The number of rows is small compared to the dataset size, but given we have both columns, we will fill text with title and vice versa in the case where NaN exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df.text.fillna(fn_df.title, inplace=True)\n",
    "fn_df.title.fillna(fn_df.text, inplace=True)\n",
    "fn_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12403\n",
       "0    12403\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataset with both True and Fake News\n",
    "n_df = pd.concat([fn_df, tn_df])\n",
    "n_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df['text2'] = pre_processor(n_df.text)\n",
    "n_df['title2'] = pre_processor(n_df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning - Using Article Text as a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = n_df.text2\n",
    "y = n_df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved 5% (~1500 examples) for final testing, rest is for Train & Hyperparameter tuning with CV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__min_df':[0.01,0.02,1], 'vect__max_df':[0.1, 0.2, 1.0]}\n",
    "model1 = ml_fit(X_train, y_train, MultinomialNB(),parameters, 'NB_Text')\n",
    "model_eval(X_test,y_test,model1,'NB_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__C':[1.0, 10, 100]}\n",
    "model2 = ml_fit(X_train, y_train,SVC(kernel='linear'), parameters, 'SVM_Text')\n",
    "model_eval(X_test,y_test,model2,'SVM_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__C':[0.1,1.0,10]}\n",
    "model3 = ml_fit(X_train, y_train,LogisticRegression(), parameters, 'LogR_Text')\n",
    "model_eval(X_test,y_test,model3,'LogR_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__learning_rate':[1], 'clf__n_estimators':[100]}\n",
    "model4 = ml_fit(X_train, y_train,GradientBoostingClassifier(), parameters, 'GrBoost_Text')\n",
    "model_eval(X_test,y_test,model4,'GrBoost_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__max_depth':[100,500,None]}\n",
    "model5 = ml_fit(X_train, y_train,DecisionTreeClassifier(), parameters, 'DecTree_Text')\n",
    "model_eval(X_test,y_test,model5,'DecTree_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__max_depth':[None]}\n",
    "model6 = ml_fit(X_train, y_train,RandomForestClassifier(), parameters, 'RForest_Text')\n",
    "model_eval(X_test,y_test,model6,'RForest_Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning - Using Article TITLE as a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = n_df.title2\n",
    "y = n_df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved 5% (~1500 examples) for final testing, rest is for Train & Hyperparameter tuning with CV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__min_df':[0.01,0.02,1], 'vect__max_df':[0.1, 0.2, 1.0]}\n",
    "model7 = ml_fit(X_train, y_train,MultinomialNB(),parameters, 'NB_Title')\n",
    "model_eval(X_test,y_test,model7,'NB_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__C':[1.0, 10, 100]}\n",
    "model8 = ml_fit(X_train, y_train,SVC(kernel='linear'), parameters, 'SVM_Title')\n",
    "model_eval(X_test,y_test,model8,'SVM_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__C':[0.01,0.1,1.0,10,100,1000]}\n",
    "model9 = ml_fit(X_train, y_train,LogisticRegression(), parameters, 'LogR_Title')\n",
    "model_eval(X_test,y_test,model9,'LogR_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__learning_rate':[0.1,1], 'clf__n_estimators':[300]}\n",
    "model10 = ml_fit(X_train, y_train,GradientBoostingClassifier(), parameters, 'GrBoost_Title')\n",
    "model_eval(X_test,y_test,model10,'GrBoost_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__max_depth':[200,400,500,1000,None]}\n",
    "model11 = ml_fit(X_train, y_train,DecisionTreeClassifier(), parameters, 'DecTree_Title')\n",
    "model_eval(X_test,y_test,model11,'DecTree_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'clf__n_estimators':[100,200,300], 'clf__max_depth':[2,3,4,None]}\n",
    "model12 = ml_fit(X_train, y_train,RandomForestClassifier(), parameters, 'RForest_Title')\n",
    "model_eval(X_test,y_test,model12,'RForest_Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning - Using BOTH Article TEXT and TITLE as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = n_df.loc[:,['text2','title2']]\n",
    "y = n_df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectorize and Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre vectorizing because have 2 features, easier this way\n",
    "vect = TfidfVectorizer()\n",
    "X_vect = sp.hstack(X.apply(lambda col: vect.fit_transform(col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved 5% (~1500 examples) for final testing, rest is for Train & Hyperparameter tuning with CV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':[1]}\n",
    "model13 = ml_fit2(X_train, y_train, MultinomialNB(),parameters, 'NB_Both')\n",
    "model_eval(X_test,y_test,model13,'NB_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0]}\n",
    "model14 = ml_fit2(X_train, y_train,SVC(kernel='linear'), parameters, 'SVM_Both')\n",
    "model_eval(X_test,y_test,model14,'SVM_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.01,0.1,1.0,10,100,1000]}\n",
    "model15 = ml_fit2(X_train, y_train,LogisticRegression(), parameters, 'LogR_Both')\n",
    "model_eval(X_test,y_test,model15,'LogR_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate':[1], 'n_estimators':[100]}\n",
    "model16 = ml_fit2(X_train, y_train,GradientBoostingClassifier(), parameters, 'GrBoost_Both')\n",
    "model_eval(X_test,y_test,model16,'GrBoost_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[500,1000,None]}\n",
    "model17 = ml_fit2(X_train, y_train,DecisionTreeClassifier(), parameters, 'DecTree_Both')\n",
    "model_eval(X_test,y_test,model17,'DecTree_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[300], 'max_depth':[None]}\n",
    "model18 = ml_fit2(X_train, y_train,RandomForestClassifier(), parameters, 'RForest_Both')\n",
    "model_eval(X_test,y_test,model18,'RForest_Both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CoronaVirus Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = pd.read_csv('corona_fake.csv', sep=';', index_col=0)\n",
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid['text2'] = pre_processor(covid.Text)\n",
    "covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_covid = covid.text2\n",
    "y_covid = np.array(covid.IsFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_covid = model3.predict(X_covid)\n",
    "covid['pred'] = y_pred_covid\n",
    "covid.loc[:,['title2','IsFake','pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_covid = sum(y_covid==y_pred_covid)/len(y_covid)*100\n",
    "accuracy_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(X_covid,y_covid,model3,'LogReg Covid Examples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
